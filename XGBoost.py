# -*- coding: utf-8 -*-
"""monthly_yearly_forecasting_sales

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mGAwVWj6mgAs014l5zge9Uppjy1CH_mN
"""

#Really need thesey
import pandas as pd
import numpy as np
from numpy import *

#Nice graphing tools
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.tools as tls

#Machine learning tools
from sklearn.model_selection import GridSearchCV,train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_percentage_error

# # Assuming your dataset is in a DataFrame named 'df' with columns 'Year', 'Month', 'Sales'
df = pd.read_csv('C:/Users/Owner/Documents/Python Project/python API/whole_sales.csv')
df.head()

#Checking the columns of the dataset
df.columns

df.info()

df.describe()

df.nunique().sort_values()

"""# Data Cleaning"""

# Checking null values
clean_df = df.copy()
clean_df.isnull().sum()*100/clean_df.shape[0]

#Removal of any Duplicate rows (if any)

counter = 0
rs,cs = clean_df.shape

clean_df.drop_duplicates(inplace=True)

if clean_df.shape==(rs,cs):
    print('\n\033[1mInference:\033[0m The dataset doesn\'t have any duplicates')
else:
    print(f'\n\033[1mInference:\033[0m Number of duplicates dropped/fixed ---> {rs-clean_df.shape[0]}')

# Formatting for sales_date and str_no

clean_df['str_no'] = clean_df['str_no'].astype(str)

clean_df['sales_date'] = pd.to_datetime(clean_df['sales_date'])

print(clean_df['str_no'].dtypes,clean_df['sales_date'].dtypes)

# Handling outlier
plt.figure(figsize=(12, 6))
#BOX PLOT DEP_NA
sns.boxplot(x='str_no', y='sales', data=clean_df, palette="Set1")

plt.subplots_adjust(hspace = 0.4, top = 0.9)

# Add labels and title
plt.xlabel('str_no')
plt.ylabel('sales')

# Show the plot
plt.show()

plt.figure(figsize=(19, 6))
#BOX PLOT CLA_NO
sns.boxplot(x='cla_no', y='sales', data=clean_df, palette="Set1")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

plt.subplots_adjust(hspace = 0.4, top = 0.9)

# Add labels and title
plt.xlabel('cla_no')
plt.ylabel('sales')

# Show the plot
plt.show()

# BOX PLOT FOR GOO_NO
# Get unique values of 'goo_no'
unique_goo_no = clean_df['goo_no'].unique()

# Calculate the middle index
middle_index = len(unique_goo_no) // 2

# Split unique values into two parts
first_part = unique_goo_no[:middle_index]
second_part = unique_goo_no[middle_index:]

# Create a condition based on the split
condition = clean_df[clean_df['goo_no'].isin(first_part)]
# Set the figure size
plt.figure(figsize=(19, 6))

# Box plot for the subset of data
sns.boxplot(x='goo_no', y='sales', data=condition, palette="Set1")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Add labels and title
plt.xlabel('goo_no')
plt.ylabel('sales')

# Adjust layout
plt.subplots_adjust(hspace=0.4, top=0.9)

# Show the plot
plt.show()

# Create a condition based on the split
condition = clean_df[clean_df['goo_no'].isin(second_part)]

plt.figure(figsize=(19, 6))

# Box plot for the subset of data
sns.boxplot(x='goo_no', y='sales', data=condition, palette="Set1")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Add labels and title
plt.xlabel('goo_no')
plt.ylabel('sales')

# Adjust layout
plt.subplots_adjust(hspace=0.4, top=0.9)

# Show the plot
plt.show()

# BOX PLOT FOR SUP_NO
# Get unique values of 'sup_no'
unique_sup_no = clean_df['sup_no'].unique()

# Calculate the middle index
middle_index = len(unique_sup_no) // 2

# Split unique values into two parts
first_part = unique_sup_no[:middle_index]
second_part = unique_sup_no[middle_index:]

# Create a condition based on the split
condition = clean_df[clean_df['sup_no'].isin(first_part)]
# Set the figure size
plt.figure(figsize=(19, 6))

# Box plot for the subset of data
sns.boxplot(x='sup_no', y='sales', data=condition, palette="Set1")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Add labels and title
plt.xlabel('sup_no')
plt.ylabel('sales')

# Adjust layout
plt.subplots_adjust(hspace=0.4, top=0.9)

# Show the plot
plt.show()

# Create a condition based on the split
condition = clean_df[clean_df['sup_no'].isin(second_part)]

# Set the figure size
plt.figure(figsize=(19, 6))

# Box plot for the subset of data
sns.boxplot(x='sup_no', y='sales', data=condition, palette="Set1")

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Add labels and title
plt.xlabel('sup_no')
plt.ylabel('sales')

# Adjust layout
plt.subplots_adjust(hspace=0.4, top=0.9)

# Show the plot
plt.show()

#TARGET ENCODING

target_encoding = clean_df.groupby('str_no')['sales'].mean()
clean_df['str_no'] = clean_df['str_no'].map(target_encoding)

target_encoding = clean_df.groupby('cla_no')['sales'].mean()
clean_df['cla_no'] = clean_df['cla_no'].map(target_encoding)

target_encoding = clean_df.groupby('goo_no')['sales'].mean()
clean_df['goo_no'] = clean_df['goo_no'].map(target_encoding)

target_encoding = clean_df.groupby('sup_no')['sales'].mean()
clean_df['sup_no'] = clean_df['sup_no'].map(target_encoding)

clean_df.head()

"""# DATA EXPLORATION

"""

exp_df = clean_df.copy()
df.head()

# FEATURE ENGINEERING
# day/time features

# Assuming 'sales_date' is in datetime format
exp_df['day_of_week'] = exp_df['sales_date'].dt.dayofweek
exp_df['month'] = exp_df['sales_date'].dt.month
exp_df['quarter'] = exp_df['sales_date'].dt.quarter
exp_df['year'] = exp_df['sales_date'].dt.year
exp_df.head()

"""# DATA SPLITTING"""

split_df = exp_df.copy()

split_df.head()

# Split the data into features (X) and target variable (y)
X = split_df[['day_of_week','month','quarter','year','str_no','cla_no']]
# 'sales_date','day_of_week','month','quarter','year'
y = split_df['sales']
# 'sales_date','day_of_week','month','quarter','year'
# Split the data into training and testing sets (e.g., 80% train, 20% test)
X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, shuffle=False)

# Display the shapes of the resulting sets
print("X_train shape:", X_train.shape)
print("X_dev shape:", X_dev.shape)
print("y_train shape:", y_train.shape)
print("y_dev shape:", y_dev.shape)

"""# MODEL TRAINING

XGBoost
"""

import xgboost as xgb

xg_reg = xgb.XGBRegressor()
parameters = {
        'n_estimators': [10, 50, 100],
        'loss':['huber'],
        'criterion': ['friedman_mse', 'squared_error'],
        'max_depth': [2, 3, 4],
        'learning_rate': [0.01, 0.1, 1],
        'min_samples_split': [2, 4, 6],
        'min_samples_leaf': [1, 2, 3]
}

# Create the grid search object
grid_search = GridSearchCV(estimator=xg_reg, param_grid=parameters, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)

# Fit the grid search to the data
grid_search.fit(X_train, y_train)

# Get the best parameters and best model
best_params = grid_search.best_params_
best_model = grid_search.best_estimator_

# Predict on the test set using the best model
y_pred = best_model.predict(X_dev)

# Evaluate the model
mse = mean_squared_error(y_dev, y_pred)
print(f'Best Hyperparameters: {best_params}')
print('MAPE score using Gradient Boosting= ',mean_absolute_percentage_error(y_dev, y_pred))
print('RMSE score using Gradient Boosting= ',mean_squared_error(y_dev, y_pred))

import pickle

with open('XGBoost_model.pkl','wb') as file:
    pickle.dump(best_model, file)