# -*- coding: utf-8 -*-
"""monthly_yearly_forecasting_sales

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mGAwVWj6mgAs014l5zge9Uppjy1CH_mN
"""

#Really need thesey
import pandas as pd
import numpy as np
from numpy import *

#Nice graphing tools
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.tools as tls

#Machine learning tools
from sklearn.model_selection import GridSearchCV,train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_absolute_percentage_error

# Fitting Polynomial Regression to the dataset
from sklearn.preprocessing import PolynomialFeatures
# Fitting Linear Regression to the dataset
from sklearn.linear_model import LinearRegression

# # Assuming your dataset is in a DataFrame named 'df' with columns 'Year', 'Month', 'Sales'
df = pd.read_csv('C:/Users/Owner/Documents/Python Project/python API/sales_&_store.csv')
df.head()

#Checking the columns of the dataset
df.columns

df.info()

df.describe()

df.nunique().sort_values()

"""# Data Cleaning"""

# Checking null values
clean_df = df.copy()
clean_df.isnull().sum()*100/clean_df.shape[0]

#Removal of any Duplicate rows (if any)

counter = 0
rs,cs = clean_df.shape

clean_df.drop_duplicates(inplace=True)

if clean_df.shape==(rs,cs):
    print('\n\033[1mInference:\033[0m The dataset doesn\'t have any duplicates')
else:
    print(f'\n\033[1mInference:\033[0m Number of duplicates dropped/fixed ---> {rs-clean_df.shape[0]}')

# Formatting for sales_date and str_no

clean_df['store'] = clean_df['store'].astype(str)

clean_df['date'] = pd.to_datetime(clean_df['date'])

print(clean_df['store'].dtypes,clean_df['date'].dtypes)

#TARGET ENCODING

target_encoding = clean_df.groupby('store')['total_sales'].mean()
clean_df['store'] = clean_df['store'].map(target_encoding)

clean_df.head()

"""# DATA EXPLORATION

"""

exp_df = clean_df.copy()
df.head()

# FEATURE ENGINEERING
# day/time features

# Assuming 'sales_date' is in datetime format
exp_df['day_of_week'] = exp_df['date'].dt.dayofweek
exp_df['month'] = exp_df['date'].dt.month
exp_df['quarter'] = exp_df['date'].dt.quarter
exp_df['year'] = exp_df['date'].dt.year
exp_df.head()

"""# DATA SPLITTING"""

split_df = exp_df.copy()

split_df.head()

# Split the data into features (X) and target variable (y)
X = split_df[['day_of_week','month','quarter','year','store']]
# 'sales_date','day_of_week','month','quarter','year'
y = split_df['total_sales']
# 'sales_date','day_of_week','month','quarter','year'
# Split the data into training and testing sets (e.g., 80% train, 20% test)
X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=0.2, shuffle=False)

# Display the shapes of the resulting sets
print("X_train shape:", X_train.shape)
print("X_dev shape:", X_dev.shape)
print("y_train shape:", y_train.shape)
print("y_dev shape:", y_dev.shape)

"""# MODEL TESTING"""

import pickle

with open('XGBoost_model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

prediction = loaded_model.predict(X_dev)

# Evaluate the model
mse = mean_squared_error(y_dev, prediction)
print(f'Best Hyperparameters: {loaded_model}')
print('MAPE score using Gradient Boosting= ',mean_absolute_percentage_error(y_dev, prediction))
print('RMSE score using Gradient Boosting= ',mean_squared_error(y_dev, prediction))